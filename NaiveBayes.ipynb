{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Na誰ve Bayes Classifier\n","This notebook presents a Na誰ve Bayes text classifier for spam detection.\n","Each section of the code is related to the relevant formula from the reference PDF."]},{"cell_type":"markdown","metadata":{},"source":["## Imports\n","We begin by importing necessary libraries."]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["import numpy as np # type: ignore\n","from collections import defaultdict\n","import re"]},{"cell_type":"markdown","metadata":{},"source":["## Dataset\n","We define the sample dataset, including emails and their labels."]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["emails = [\"Win a free lottery now\", \"Buy money online cheap\", \n","          \"You won free cash prize\", \"Meet me at 5 pm\", \"Hello, how are you?\"]\n","labels = [1, 1, 1, 0, 0]  # 1 = Spam, 0 = Not Spam"]},{"cell_type":"markdown","metadata":{},"source":["## Tokenization\n","We define a function to tokenize the emails by extracting words."]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["def tokenize(text):\n","    \"\"\"Convert text into a list of lowercase words.\"\"\"\n","    return re.findall(r'\\b\\w+\\b', text.lower())"]},{"cell_type":"markdown","metadata":{},"source":["## Building Vocabulary and Counting Words\n","We count occurrences of words in spam and non-spam emails.\n","\n","Formula (Multinomial Na誰ve Bayes):\n","\n","$$ P(x_i | c) = \\frac{\\text{count}(x_i, c) + \\alpha}{\\sum \\text{count}(w, c) + \\alpha V} $$\n","\n","Where:\n","\n","\n","$ P(x_i | c) $ is the probability of word $x_i$ appearing in class $c$ (Spam or Not Spam).\n","\n","$ \\text{count}(x_i, c) $ is the number of times word $x_i$ appears in emails belonging to class $c$ (Spam or Not Spam).\n","\n","$ \\sum \\text{count}(w, c) $ is the total count of all words $w$ in class $c$, summing over all words in that class.\n","\n","$\\alpha $ is Laplace smoothing parameter (to prevent zero probabilities).\n","\n","$V$ is the total number of unique words (vocabulary size).\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Mapping Formula Components to Code\n","\n","\n","\\begin{array}{|c|c|}\n","\\hline\n","\\textbf{Formula Component} & \\textbf{Code Representation} \\\\\n","\\hline\n","P(x_i | c) & \\text{Computed as word probability later} \\\\\n","\\hline\n","\\text{count}(x_i, c) & \\texttt{word\\_counts[label][word]} \\\\\n","\\hline\n","\\sum \\text{count}(w, c) & \\texttt{sum(word\\_counts[label].values())} \\\\\n","\\hline\n","V \\text{ (vocabulary size)} & \\texttt{len(vocab)} \\\\\n","\\hline\n","\\alpha \\text{ (Laplace smoothing)} & \\texttt{alpha = 1} \\\\\n","\\hline\n","\\end{array}\n","\n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["vocab = set()\n","word_counts = {0: defaultdict(int), 1: defaultdict(int)}\n","class_counts = {0: 0, 1: 0}\n","\n","for email, label in zip(emails, labels):\n","    words = tokenize(email)\n","    class_counts[label] += 1\n","    for word in words:\n","        vocab.add(word)\n","        word_counts[label][word] += 1"]},{"cell_type":"markdown","metadata":{},"source":["## Convert Vocabulary to List"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["vocab = list(vocab)\n","total_words = len(vocab)"]},{"cell_type":"markdown","metadata":{},"source":["## Calculate Priors\n","We compute the prior probabilities for spam and non-spam emails.\n","\n","Bayes' Theorem:\n","\n","$$ P(A | B) = \\frac{P(B | A) P(A)}{P(B)} $$"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["total_samples = len(emails)\n","P_spam = class_counts[1] / total_samples\n","P_not_spam = class_counts[0] / total_samples"]},{"cell_type":"markdown","metadata":{},"source":["## Compute Likelihoods with Laplace Smoothing\n","To prevent zero probabilities, we apply Laplace smoothing.\n","\n","Formula:\n","\n","$$ P(x_i | c) = \\frac{\\text{count}(x_i, c) + \\alpha}{\\sum \\text{count}(w, c) + \\alpha V} $$"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["alpha = 1\n","word_probs = {0: {}, 1: {}}\n","\n","for word in vocab:\n","    word_probs[0][word] = (word_counts[0][word] + alpha) / (sum(word_counts[0].values()) + alpha * total_words)\n","    word_probs[1][word] = (word_counts[1][word] + alpha) / (sum(word_counts[1].values()) + alpha * total_words)"]},{"cell_type":"markdown","metadata":{},"source":["## Na誰ve Bayes Prediction Function\n","Formula:\n","\n","$$ \\log P(c | x_1, ..., x_n) = \\log P(c) + \\sum_{i=1}^{n} \\log P(x_i | c) $$"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["def predict(email):\n","    words = tokenize(email)\n","    log_prob_spam = np.log(P_spam)\n","    log_prob_not_spam = np.log(P_not_spam)\n","\n","    for word in words:\n","        if word in vocab:\n","            log_prob_spam += np.log(word_probs[1][word])\n","            log_prob_not_spam += np.log(word_probs[0][word])\n","\n","    return 1 if log_prob_spam > log_prob_not_spam else 0 #argmix"]},{"cell_type":"markdown","metadata":{},"source":["## Testing the Classifier"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["New Email: 'Get free cash now'\n","Prediction: Spam\n"]}],"source":["new_email = \"Get free cash now\"\n","prediction = predict(new_email)\n","print(f\"New Email: '{new_email}'\")\n","print(\"Prediction:\", \"Spam\" if prediction == 1 else \"Not Spam\")"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":4}
